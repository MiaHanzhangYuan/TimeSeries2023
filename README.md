# TimeSeries2023
# Overview

In this study, we aim to analyze students' financial status data over years and personal information to get insights into school's related policy making strategy. This project would imply time-series machine learning models and explore more deep learning network structures.

# Literature Review
This project would be a time series problem which could be modelled by DL network; I am planning to read at least two paper a week, with a reading note written, and run the code, if available. These two papers contain one from Time Series's persective to know basically how to solve the problem and the other one from deep learning structure's perspective to get more idea about improving the model. I would read more if time permits.

## Time Series Papers
*[Financial time series forecasting with deep learning: A systematic literature review: 2005–2019](https://arxiv.org/pdf/1911.13288.pdf)

*[Financial time series forecasting with machine learning techniques: A survey](https://research.bond.edu.au/en/publications/financial-time-series-forecasting-with-machine-learning-technique)

*[Financial Time Series Forecasting – A Deep Learning Approach](http://www.ijmlc.org/vol7/632-P17.pdf)

*[Training noise-resilient recurrent photonic networks for financial time series analysis](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9287649)

*[Imaging feature-based clustering of financial time series](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0288836)

*[Financial Time-Series Data Analysis Using Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/7979885)

*[Financial Time Series Prediction Based on Deep Learning](https://link.springer.com/article/10.1007/s11277-017-5086-2)

*[Deep learning for multivariate financial time series](https://www.diva-portal.org/smash/get/diva2:820891/FULLTEXT01.pdf)

*[Developing a deep learning framework with two-stage feature selection for multivariate financial time series forecasting](https://www.sciencedirect.com/science/article/abs/pii/S0957417420300634)

## Deep Learning Papers
*[Attention is all you need](https://github.com/Data-ScienceHub/gpce-covid/blob/main/papers/Attension%20is%20all%20You%20Need.pdf)

*[Sequence to Sequence Learning with Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html)

*[Long Short-Term Memory](https://ieeexplore.ieee.org/abstract/document/6795963)

*[Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)

*[QUASI-RECURRENT NEURAL NETWORKS](https://arxiv.org/abs/1611.01576)

*[You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)

*[Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)

*[Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion](https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf)

*[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661)

# Methodology

## Data Prepocessing
Data prepocessing would be an important part of this project, which includes the steps we need to follow to transform or encode data so that it may be easily parsed by the machine. This would be the first step after we actually have access to the dataset. The majority of the real-world datasets for machine learning are highly susceptible to be missing, inconsistent, and noisy due to the heterogeneous origin. Data prepocessing should contain the following part:
### Data Cleaning
Missing values;
Noisy Data; 
Removing outliers
### Data Transformation
Generalization; 
Normalization
### Label Encoding
One-hot encoding

## Feature Selection
After having prepocessing, we need to do feature selection. This dataset would contain many variables, not every of them would be useful in our modelling part. Thus finding right approach to select the useful variables with explainablity is crucial for the following modelling.
We can first try some statistical methods, such as principle component analysis, which is a widely used dimensionality reduction method, by transforming a large set of variables into a smaller one that still contains most of the information in the large set. 
# Goal of this project
The primary goal of this project is to have this paper published.
## subgoal if this project
Increase coding ability and know how to work in group.

# Assignments
## Effort
At least 20 hrs per week's effort would be commited to this project. By the end of the semester, a series of reading notes would record my learning track of related fields.
## Schedule
The further part should still be decided accordingly, but it must be clear that all related paper work should be finished by Nov 24th.
 
| week             | Content       | Code                       | paper progress |
| -------------    | ------------- |----------------------------|--------------- |
| week of Oct 2    | paper 1,2     |Data Prepocessing Beginning |Begin to write the introduction |
| week of Oct 9    | paper 3,4     |Data Final review and usable evaluation    |Write the review part |
| week of Oct 16   | paper 5,6     |Model Building              |  |
| week of Oct 23   | paper 7,8     |Model Building              |  |
| week of Oct 30   | paper 9,10    |Model Building              |  |
| week of Nov 6    |               |Model Building              |  |
| week of Nov 13   |               |                            |  |
| week of Nov 20   |               |                            |  |
| week of Nov 27   | paper reading |                            |Paper submission |
| week of Dec 4    | paper reading |                            |                |



